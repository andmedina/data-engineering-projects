{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "- Read CSV, JSON, and XML file types\n",
    "- Extract the required data from the different file types. \n",
    "- Transform data to the required format. \n",
    "- Save the transformed data in a ready-to-load format, which can be loaded into an RDBMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and unzip file in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Define the URL and the local filename\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\"\n",
    "local_filename = \"source.zip\"\n",
    "\n",
    "# Download the file from the URL\n",
    "urllib.request.urlretrieve(url, local_filename)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(local_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime \n",
    "import os\n",
    "\n",
    "#Global variables used by various functions\n",
    "log_file = \"log_file.txt\" #store all logs\n",
    "target_file = \"transformed_data.csv\" #Store final output data that can be loaded to a database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) #If we explore the json file we can see that each new-line is an json object. So, this parameter indiicates a newline-delimter. \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(directory):\n",
    "    extracted_data = pd.DataFrame(columns=['name', 'height', 'weight'])  # create an empty data frame to hold extracted data\n",
    "    \n",
    "    # Process all CSV files in the directory\n",
    "    for csvfile in glob.glob(os.path.join(directory, \"*.csv\")):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
    "    \n",
    "    # Process all JSON files in the directory\n",
    "    for jsonfile in glob.glob(os.path.join(directory, \"*.json\")):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
    "    \n",
    "    # Process all XML files in the directory\n",
    "    for xmlfile in glob.glob(os.path.join(directory, \"*.xml\")):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True)\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are interested in working with international units so pounds will go to kilgram and inches to centimeters.\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file, transformed_data): \n",
    "    transformed_data.to_csv(target_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING ETL PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "     name  height  weight\n",
      "0    alex    1.67   51.25\n",
      "1    ajay    1.82   61.91\n",
      "2   alice    1.76   69.41\n",
      "3    ravi    1.73   64.56\n",
      "4     joe    1.72   65.45\n",
      "5    alex    1.67   51.25\n",
      "6    ajay    1.82   61.91\n",
      "7   alice    1.76   69.41\n",
      "8    ravi    1.73   64.56\n",
      "9     joe    1.72   65.45\n",
      "10   alex    1.67   51.25\n",
      "11   ajay    1.82   61.91\n",
      "12  alice    1.76   69.41\n",
      "13   ravi    1.73   64.56\n",
      "14    joe    1.72   65.45\n",
      "15   jack    1.74   55.93\n",
      "16    tom    1.77   64.18\n",
      "17  tracy    1.78   61.90\n",
      "18   john    1.72   50.97\n",
      "19   jack    1.74   55.93\n",
      "20    tom    1.77   64.18\n",
      "21  tracy    1.78   61.90\n",
      "22   john    1.72   50.97\n",
      "23   jack    1.74   55.93\n",
      "24    tom    1.77   64.18\n",
      "25  tracy    1.78   61.90\n",
      "26   john    1.72   50.97\n",
      "27  simon    1.72   50.97\n",
      "28  jacob    1.70   54.73\n",
      "29  cindy    1.69   57.81\n",
      "30   ivan    1.72   51.77\n",
      "31  simon    1.72   50.97\n",
      "32  jacob    1.70   54.73\n",
      "33  cindy    1.69   57.81\n",
      "34   ivan    1.72   51.77\n",
      "35  simon    1.72   50.97\n",
      "36  jacob    1.70   54.73\n",
      "37  cindy    1.69   57.81\n",
      "38   ivan    1.72   51.77\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract('extracted_files') \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduate_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
